{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Games\n",
    "\n",
    "It has been widely publicized that machine learning has achieved great success in game playing during recent years, including ancient games like [GO](https://en.wikipedia.org/wiki/Go_(game) to modern computer games like [Starcraft](https://starcraft2.com/en-us/). For news, see:\n",
    "\n",
    "[The awful frustration of a teenage Go champion playing Google’s AlphaGo](https://qz.com/993147/the-awful-frustration-of-a-teenage-go-champion-playing-googles-alphago/)\n",
    "\n",
    "[AI defeated humans at StarCraft II. Here’s why it matters.](https://www.wired.com/story/deepmind-beats-pros-starcraft-another-triumph-bots/)\n",
    "\n",
    "\n",
    "We don't have enough background for understanding these complicated algorithms yet. In this assignment, we are going to see how decision trees can help understand some simple games including TIC-TAC-TOE and chess(King-Rook vs. King).\n",
    "\n",
    "Make sure you have installed [Pandas](https://pandas.pydata.org/), [numpy](http://www.numpy.org/), [graphviz](https://www.graphviz.org/) and [Scikit Learn](https://scikit-learn.org/) before running the script.\n",
    "\n",
    "```bash\n",
    "    conda install pandas numpy graphviz scikit-learn\n",
    "```\n",
    "or\n",
    "\n",
    "```bash\n",
    "    pip3 install pandas numpy graphviz scikit-learn\n",
    "```\n",
    "\n",
    "You may find the following links useful:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/tree.html and\n",
    "http://scikitlearn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tic-Tac-Toe Endgame Classification\n",
    "For introduction and rules of Tic-Tac-Toe, see [Wiki page](https://en.wikipedia.org/wiki/Tic-tac-toe). \n",
    "\n",
    "<img src=\"tic_tac.jpg\" width=\"400\">\n",
    "\n",
    "We will use Tic-Tac-Toe Endgame Data Set from UCI machine learning repository. (See introduction [here](https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame)). This database encodes the complete set of possible board configurations at the end of tic-tac-toe games, where \"x\" is assumed to have played first. The target concept is \"win for x\" (i.e., true when \"x\" has one of 8 possible ways to create a \"three-in-a-row\"). \n",
    "\n",
    "The dataset has 9 attributes, each indicating the status of each squre. ('x' if \"x\" is placed, 'o' if \"o\" is placed and 'b' if blank). Examples of the dataset can be seen here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_left_sqr</th>\n",
       "      <th>top_middle_sqr</th>\n",
       "      <th>top_right_sqr</th>\n",
       "      <th>mid_left_sqr</th>\n",
       "      <th>mid_mid_sqr</th>\n",
       "      <th>mid_right_sqr</th>\n",
       "      <th>btm_left_sqr</th>\n",
       "      <th>btm_mid_sqr</th>\n",
       "      <th>btm_right_sqr</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    top_left_sqr top_middle_sqr top_right_sqr mid_left_sqr mid_mid_sqr  \\\n",
       "879            b              x             x            x           x   \n",
       "496            b              x             o            x           x   \n",
       "14             x              x             x            o           x   \n",
       "546            b              o             x            o           b   \n",
       "55             x              x             x            b           o   \n",
       "785            o              x             o            b           o   \n",
       "202            x              o             b            x           b   \n",
       "566            b              o             o            x           x   \n",
       "940            b              b             o            b           x   \n",
       "299            o              x             x            o           x   \n",
       "\n",
       "    mid_right_sqr btm_left_sqr btm_mid_sqr btm_right_sqr     class  \n",
       "879             o            o           o             o  negative  \n",
       "496             x            o           o             b  positive  \n",
       "14              o            o           o             x  positive  \n",
       "546             x            x           o             x  positive  \n",
       "55              x            b           o             o  positive  \n",
       "785             x            o           x             x  negative  \n",
       "202             o            x           x             o  positive  \n",
       "566             x            b           x             o  positive  \n",
       "940             o            x           x             o  negative  \n",
       "299             o            x           x             o  positive  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "tic_toc = pd.read_csv('./tic-tac-toe.data', header=None) #read dataset\n",
    "tic_toc.columns = ['top_left_sqr', 'top_middle_sqr', 'top_right_sqr',\n",
    "             'mid_left_sqr', 'mid_mid_sqr', 'mid_right_sqr', \n",
    "             'btm_left_sqr', 'btm_mid_sqr', 'btm_right_sqr',\n",
    "             'class'] # rename each column\n",
    "tic_toc = shuffle(tic_toc, random_state = 0) # shuffle the dataset\n",
    "tic_toc.head(10) #print the top ten entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing\n",
    "To get these features and labels fit into learning models, we need to convert them into integer or boolean variables. For features with $k$ possible values, a common trick is one-hot encoding (dummy variables). Suppose feature $X$ can take $k$ possible values, we encode it into a $k$-dimensional boolean vector where there is a one at location $i$ if $X = 1$ and zeros elsewhere. Suppose $X$ can take $5$ possible values and $X = 3$. Then\n",
    "\n",
    "$$ Enc(X) = (0, 0, 1, 0, 0) $$\n",
    "\n",
    "We do this for each feature with $k = 3$ and convert labels to $\\{0, 1\\}$. Note that for one hot encoding, we can always drop the first dimension since if all others are zeros, we know it has to be one.\n",
    "\n",
    "Next we randomly pick $70\\%$ of the data to  be our training set and the remaining for testing.\n",
    "\n",
    "After this, each training example has $18$ features. Training set looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_left_sqr_o</th>\n",
       "      <th>top_left_sqr_x</th>\n",
       "      <th>top_middle_sqr_o</th>\n",
       "      <th>top_middle_sqr_x</th>\n",
       "      <th>top_right_sqr_o</th>\n",
       "      <th>top_right_sqr_x</th>\n",
       "      <th>mid_left_sqr_o</th>\n",
       "      <th>mid_left_sqr_x</th>\n",
       "      <th>mid_mid_sqr_o</th>\n",
       "      <th>mid_mid_sqr_x</th>\n",
       "      <th>mid_right_sqr_o</th>\n",
       "      <th>mid_right_sqr_x</th>\n",
       "      <th>btm_left_sqr_o</th>\n",
       "      <th>btm_left_sqr_x</th>\n",
       "      <th>btm_mid_sqr_o</th>\n",
       "      <th>btm_mid_sqr_x</th>\n",
       "      <th>btm_right_sqr_o</th>\n",
       "      <th>btm_right_sqr_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     top_left_sqr_o  top_left_sqr_x  top_middle_sqr_o  top_middle_sqr_x  \\\n",
       "879               0               0                 0                 1   \n",
       "496               0               0                 0                 1   \n",
       "14                0               1                 0                 1   \n",
       "546               0               0                 1                 0   \n",
       "55                0               1                 0                 1   \n",
       "\n",
       "     top_right_sqr_o  top_right_sqr_x  mid_left_sqr_o  mid_left_sqr_x  \\\n",
       "879                0                1               0               1   \n",
       "496                1                0               0               1   \n",
       "14                 0                1               1               0   \n",
       "546                0                1               1               0   \n",
       "55                 0                1               0               0   \n",
       "\n",
       "     mid_mid_sqr_o  mid_mid_sqr_x  mid_right_sqr_o  mid_right_sqr_x  \\\n",
       "879              0              1                1                0   \n",
       "496              0              1                0                1   \n",
       "14               0              1                1                0   \n",
       "546              0              0                0                1   \n",
       "55               1              0                0                1   \n",
       "\n",
       "     btm_left_sqr_o  btm_left_sqr_x  btm_mid_sqr_o  btm_mid_sqr_x  \\\n",
       "879               1               0              1              0   \n",
       "496               1               0              1              0   \n",
       "14                1               0              1              0   \n",
       "546               0               1              1              0   \n",
       "55                0               0              1              0   \n",
       "\n",
       "     btm_right_sqr_o  btm_right_sqr_x  \n",
       "879                1                0  \n",
       "496                0                0  \n",
       "14                 0                1  \n",
       "546                0                1  \n",
       "55                 1                0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tic_toc.loc[tic_toc['class'] == 'positive', 'class'] = 1 #change labels from words to integers\n",
    "tic_toc.loc[tic_toc['class'] == 'negative', 'class'] = 0\n",
    "X = pd.get_dummies(tic_toc.iloc[:, :-1], drop_first=True) # one-hot encoding\n",
    "y = tic_toc['class'].astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0) # split the dataset into training and testing sets\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "Using information gain as you splitting criterion, set the maximum depth from 1 to 12. Plot the training and testing error with respect to each maximum depth. Justify your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e1a270d4d21e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0ml_trn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0ml_tst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_trn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "Err_Train = np.zeros(12)\n",
    "Err_Test = np.zeros(12)\n",
    "indices = range(1,13)\n",
    "\n",
    "#==================Your code ===================\n",
    "\n",
    "for i in indices:\n",
    "    clf1 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=i)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    Err_Train[i-1] = 1 - accuracy_score(y_train, clf1.predict(X_train))\n",
    "    Err_Test[i-1] = 1 - accuracy_score(y_test, clf1.predict(X_test))\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "l_trn = 1 - accuracy_score(y_train, clf.predict(X_train))\n",
    "l_tst = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "print(l_trn)\n",
    "#==============================================\n",
    "plt.plot(indices,Err_Train, label = \"training\")\n",
    "plt.plot(indices,Err_Test, label = \"testing\")\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can clearly see how in all depths, the training error is always less than the testing error. This is expected that we have less training error compared to testing error. We can also observe that from depths 0 to 8, the results keeps getting more accurate. However, we can see how at depth 9-12 it has more errors. This explains about overfitting, in which as we get more depth we no longer learn about the process, and only produce noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "Using GINI impurity as you splitting criterion, set the maximum depth from 1 to 12. Plot the training and testing error with respect to each maximum depth. Is it the same with information gain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12316bee0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Err_Train = np.zeros(12)\n",
    "Err_Test = np.zeros(12)\n",
    "indices = range(1,13)\n",
    "#==================Your code ===================\n",
    "\n",
    "for i in indices:\n",
    "    clf2 = DecisionTreeClassifier(criterion=\"gini\", max_depth=i)\n",
    "    clf2.fit(X_train, y_train)\n",
    "    Err_Train[i-1] = 1 - accuracy_score(y_train, clf2.predict(X_train))\n",
    "    Err_Test[i-1] = 1 - accuracy_score(y_test, clf2.predict(X_test))\n",
    "\n",
    "\n",
    "#==============================================\n",
    "\n",
    "plt.plot(indices,Err_Train, label = \"training\")\n",
    "plt.plot(indices,Err_Test, label = \"testing\")\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the two plots above, we can see that the plot from using Gini impurity as splitting criterion is pretty similar to the plot with information gain. We can also see the overfitting in this plot, for example in how depth of 7 is more accurate then depth of 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "Pick any tree you have learned above. Let \"model_dtc\" be the model you have created using scikit-learn. The following script will print the tree into file 'TIC-TOC-TOE.pdf'. What is the root node? Explain whether it coincides with your intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TIC-TOC-TOE.pdf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf1, out_file=None, \n",
    "                    feature_names = X.columns,\n",
    "                    class_names= 'win',  \n",
    "                    filled=True, rounded=True,  \n",
    "                    special_characters=True)  \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"TIC-TOC-TOE\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root node is mid_mid_sqr_o, which is tells us whether the middle-middle square has a 'o' or not. This coincides with my intuition, in which I am thinking that the root node will be checking the middle-middle square, on whether it is 'o', or 'x', or blank. This is because we know that the middle-middle square would have the highest chance of being involved (or filled) in the game as there are more ways to win when the middle square is filled. So we can also see how it will have the most information on what the outcome would be, thus being the root node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chess(King-Rook vs. King) Endgame Classification\n",
    "For introduction and rules of Chess, see [Wiki page](https://en.wikipedia.org/wiki/Chess). \n",
    "<img src=\"chess.png\" width=\"400\">\n",
    "\n",
    "We will use Chess(King-Rook vs. King) Data Set from UCI machine learning repository. (See introduction [here](https://archive.ics.uci.edu/ml/datasets/Chess+(King-Rook+vs.+King)). This database has 28056 possible instances of chess endgame situations where the white has a king and a rook and the black has only a king. The goal is to determine what is the minimum depth for the white to win.\n",
    "\n",
    "The dataset has 6 attributes. Each of them can take 8 values, listed as following:\n",
    "\n",
    "1. White King file (column a - h) \n",
    "2. White King rank (row 1 - 8) \n",
    "3. White Rook file \n",
    "4. White Rook rank \n",
    "5. Black King file \n",
    "6. Black King rank \n",
    "\n",
    "And the label is the least number of steps that the white must use to win. (draw if more than 16). The following is how the data set looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wkf</th>\n",
       "      <th>wkr</th>\n",
       "      <th>wrf</th>\n",
       "      <th>wrr</th>\n",
       "      <th>bkf</th>\n",
       "      <th>bkr</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22363</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>g</td>\n",
       "      <td>7</td>\n",
       "      <td>fourteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18474</th>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>6</td>\n",
       "      <td>e</td>\n",
       "      <td>6</td>\n",
       "      <td>thirteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24609</th>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>4</td>\n",
       "      <td>fourteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6969</th>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>5</td>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "      <td>nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16585</th>\n",
       "      <td>d</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>6</td>\n",
       "      <td>twelve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5441</th>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "      <td>eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "      <td>nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27543</th>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "      <td>6</td>\n",
       "      <td>fifteen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      wkf  wkr wrf  wrr bkf  bkr     class\n",
       "22363   b    2   d    1   g    7  fourteen\n",
       "18474   c    2   a    6   e    6  thirteen\n",
       "24609   d    1   d    2   f    4  fourteen\n",
       "3668    d    2   h    1   a    2      five\n",
       "6969    c    1   f    5   g    1      nine\n",
       "4007    d    1   b    4   h    1       six\n",
       "16585   d    3   h    1   c    6    twelve\n",
       "5441    c    2   b    4   g    1     eight\n",
       "6712    b    1   e    3   g    1      nine\n",
       "27543   d    1   f    4   e    6   fifteen"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess = pd.read_csv('./krkopt_data.txt', header=None) # read data \n",
    "chess.columns = ['wkf', 'wkr', 'wrf', 'wrr', 'bkf', 'bkr', 'class'] # rename columns\n",
    "chess = shuffle(chess, random_state = 0) # shuffle the data \n",
    "chess.head(10) # print top 10 labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we convert these values into boolean features using the same one-hot encoding trick we described for TIC-TAC-TOE game. Deleting symmetric features (the dataset only has white kings in the bottom-left corner) for the white king and drop the first for the others, we get a data set with $36$ boolean features. \n",
    "\n",
    "Next we randomly pick $70\\%$ of the data to  be our training set and the remaining for testing. Training set looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wkf_a</th>\n",
       "      <th>wkf_b</th>\n",
       "      <th>wkf_c</th>\n",
       "      <th>wkf_d</th>\n",
       "      <th>wkr_1</th>\n",
       "      <th>wkr_2</th>\n",
       "      <th>wkr_3</th>\n",
       "      <th>wkr_4</th>\n",
       "      <th>wrf_b</th>\n",
       "      <th>wrf_c</th>\n",
       "      <th>...</th>\n",
       "      <th>bkf_f</th>\n",
       "      <th>bkf_g</th>\n",
       "      <th>bkf_h</th>\n",
       "      <th>bkr_2</th>\n",
       "      <th>bkr_3</th>\n",
       "      <th>bkr_4</th>\n",
       "      <th>bkr_5</th>\n",
       "      <th>bkr_6</th>\n",
       "      <th>bkr_7</th>\n",
       "      <th>bkr_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18073</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8869</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11300</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10037</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17803</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13751</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wkf_a  wkf_b  wkf_c  wkf_d  wkr_1  wkr_2  wkr_3  wkr_4  wrf_b  wrf_c  \\\n",
       "3409       0      0      0      1      0      0      1      0      0      0   \n",
       "18073      0      0      1      0      1      0      0      0      0      0   \n",
       "3544       0      0      0      1      1      0      0      0      0      0   \n",
       "8869       0      0      1      0      0      1      0      0      1      0   \n",
       "11300      0      0      1      0      0      1      0      0      0      0   \n",
       "10037      0      0      0      1      0      0      1      0      0      0   \n",
       "18156      0      0      1      0      1      0      0      0      0      0   \n",
       "17803      0      1      0      0      0      1      0      0      0      0   \n",
       "13751      0      1      0      0      0      1      0      0      0      0   \n",
       "3240       0      0      0      1      1      0      0      0      0      0   \n",
       "\n",
       "       ...  bkf_f  bkf_g  bkf_h  bkr_2  bkr_3  bkr_4  bkr_5  bkr_6  bkr_7  \\\n",
       "3409   ...      0      0      0      0      0      0      0      0      0   \n",
       "18073  ...      0      0      1      0      0      0      0      0      1   \n",
       "3544   ...      0      0      0      0      0      0      0      0      0   \n",
       "8869   ...      0      1      0      0      1      0      0      0      0   \n",
       "11300  ...      0      0      0      0      0      0      0      0      1   \n",
       "10037  ...      0      0      1      0      0      0      0      0      0   \n",
       "18156  ...      0      0      0      0      1      0      0      0      0   \n",
       "17803  ...      0      0      1      0      0      0      0      1      0   \n",
       "13751  ...      0      0      1      0      0      0      1      0      0   \n",
       "3240   ...      0      0      0      1      0      0      0      0      0   \n",
       "\n",
       "       bkr_8  \n",
       "3409       0  \n",
       "18073      0  \n",
       "3544       0  \n",
       "8869       0  \n",
       "11300      0  \n",
       "10037      1  \n",
       "18156      0  \n",
       "17803      0  \n",
       "13751      0  \n",
       "3240       0  \n",
       "\n",
       "[10 rows x 36 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "d_wkf = pd.get_dummies(chess['wkf'], prefix='wkf')   # one hot encoding\n",
    "d_wkr = pd.get_dummies(chess['wkr'], prefix='wkr')\n",
    "d_wrf = pd.get_dummies(chess['wrf'], prefix='wrf', drop_first=True)\n",
    "d_wrr = pd.get_dummies(chess['wrr'], prefix='wrr', drop_first=True)\n",
    "d_bkf = pd.get_dummies(chess['bkf'], prefix='bkf', drop_first=True)\n",
    "d_bkr = pd.get_dummies(chess['bkr'], prefix='bkr', drop_first=True)\n",
    "chess_new = pd.concat([d_wkf, d_wkr, d_wrf, d_wrr, d_bkf, d_bkr, chess['class']], axis=1) # get new dataset with new features\n",
    "X = chess_new.iloc[:, :-1] \n",
    "y = chess_new['class']\n",
    "le = LabelEncoder()  # change labels into integers \n",
    "y = le.fit_transform(y) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # split the dataset into training and testing sets\n",
    "X_train.head(10) # print top 10 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 \n",
    "Using information gain as you splitting criterion, set the maximum depth from 20 to 35. Plot the training and testing error with respect to each maximum depth. When is the maximum training accuracy achieved? When is the maximum testing accuracy achieved? Explain this phenomenon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(criterion='entropy', max_depth=20)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=21)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=22)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=23)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=24)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=25)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=26)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=27)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=28)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=29)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=30)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=31)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=32)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=33)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=34)\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=35)\n",
      "Max training accuracy: 1.0\n",
      "Max training depth accuracy: 31\n",
      "Max testing accuracy: 0.5452061304502792\n",
      "Max testing depth accuracy: 34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x123fc6bb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 20\n",
    "end = 36\n",
    "indices = range(start,end)\n",
    "Err_Train = np.zeros(end - start)\n",
    "Err_Test = np.zeros(end - start)\n",
    "#==================Your code ===================\n",
    "\n",
    "max_accuracy_train, max_accuracy_depth_train, max_accuracy_test, max_accuracy_depth_test = 0, 0, 0, 0\n",
    "\n",
    "for i in indices:\n",
    "    clf4 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=i)\n",
    "    clf4.fit(X_train, y_train)\n",
    "    Err_Train[i-start] = 1 - accuracy_score(y_train, clf4.predict(X_train))\n",
    "    Err_Test[i-start] = 1 - accuracy_score(y_test, clf4.predict(X_test))\n",
    "    \n",
    "    if ((1 - Err_Train[i-start]) > max_accuracy_train):\n",
    "        max_accuracy_train = (1 - Err_Train[i-start])\n",
    "        max_accuracy_depth_train = i\n",
    "        \n",
    "    if ((1 - Err_Test[i-start]) > max_accuracy_test):\n",
    "        max_accuracy_test = (1 - Err_Test[i-start])\n",
    "        max_accuracy_depth_test = i\n",
    "        \n",
    "        \n",
    "print(\"Max training accuracy:\", max_accuracy_train)\n",
    "print(\"Max training depth accuracy:\", max_accuracy_depth_train)       \n",
    "print(\"Max testing accuracy:\", max_accuracy_test)\n",
    "print(\"Max testing depth accuracy:\", max_accuracy_depth_test)      \n",
    "#==============================================\n",
    "\n",
    "plt.plot(indices,Err_Train, label = \"training\")\n",
    "plt.plot(indices,Err_Test, label = \"testing\")\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum training accuracy is reached at around depth of 31. Beyond the depth of 31, there is no improvement in accuracy, as perfect accuracy of 1 has been achieved. The maximum testing accuracy is achieved at depth 23, at accuracy of .545. This plot tells you a lot about overfitting. This means that as the model gets more complex, at one point you just stop learning about the process, but only learn about the noise, which may then make the result to be less accurate.\n",
    "\n",
    "On a side note, in this plot, we can also see how the we perform better on the training set, compared to the testing set, and this is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "Let's take a step further towards real AI applications. For the same game set-up, suppose you have a perfect decision tree which can tell you the minimum number of moves the white need to win. Given any instance, can you tell us which move is the optimal move for the white?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we can tell the optimal move by performing trials and errors. Given any instance, we can try each of the various moves available, and in each move, we put into the system and check on what is the minimum number of moves left needed for white to win. Then, we choose the move that has the minimum number of moves needed, and then iterate from there, until we win. In the end, we would have found out the optimal move for the white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
