{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality Classification\n",
    "\n",
    "In this assignment, we will use logistic regression to judge the quality of wines. The dataset is taken from UCI machine learning repository. For description of the dataset, see [here](https://archive.ics.uci.edu/ml/datasets/wine+quality).\n",
    "\n",
    "Attributes of the dataset are listed as following:\n",
    "1. fixed acidity \n",
    "2. volatile acidity \n",
    "3. citric acid \n",
    "4. residual sugar \n",
    "5. chlorides \n",
    "6. free sulfur dioxide \n",
    "7. total sulfur dioxide \n",
    "8. density \n",
    "9. pH \n",
    "10. sulphates \n",
    "11. alcohol \n",
    "\n",
    "Output variable (based on sensory data): \n",
    "12. quality (score between 0 and 10)\n",
    "\n",
    "The following code loads the dataset, and the dataset looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>5.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.031</td>\n",
       "      <td>53.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.99321</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.46</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.58</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.044</td>\n",
       "      <td>42.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.301</td>\n",
       "      <td>24.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.99930</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.42</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.044</td>\n",
       "      <td>60.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.99562</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.049</td>\n",
       "      <td>59.5</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.99500</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.047</td>\n",
       "      <td>42.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.99283</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>31.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.99815</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>20.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.56</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.27</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.063</td>\n",
       "      <td>39.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.63</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.026</td>\n",
       "      <td>29.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.78</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "4731            5.3              0.31         0.38            10.5      0.031   \n",
       "937             6.1              0.36         0.58            15.0      0.044   \n",
       "1217            8.0              0.61         0.38            12.1      0.301   \n",
       "3296            6.6              0.28         0.42             8.2      0.044   \n",
       "4524            6.6              0.16         0.25             9.8      0.049   \n",
       "3640            6.8              0.19         0.33             4.9      0.047   \n",
       "785             7.6              0.30         0.27            10.6      0.039   \n",
       "393             7.3              0.24         0.43             2.0      0.021   \n",
       "562             7.7              0.34         0.27             8.8      0.063   \n",
       "1285            7.8              0.16         0.41             1.7      0.026   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "4731                 53.0                 140.0  0.99321  3.34       0.46   \n",
       "937                  42.0                 115.0  0.99780  3.15       0.51   \n",
       "1217                 24.0                 220.0  0.99930  2.94       0.48   \n",
       "3296                 60.0                 196.0  0.99562  3.14       0.48   \n",
       "4524                 59.5                 137.0  0.99500  3.16       0.38   \n",
       "3640                 42.0                 130.0  0.99283  3.12       0.56   \n",
       "785                  31.0                 119.0  0.99815  3.27       0.30   \n",
       "393                  20.0                  69.0  0.99000  3.08       0.56   \n",
       "562                  39.0                 184.0  0.99690  3.09       0.63   \n",
       "1285                 29.0                 140.0  0.99100  3.02       0.78   \n",
       "\n",
       "      alcohol  quality  \n",
       "4731     11.7        6  \n",
       "937       9.0        5  \n",
       "1217      9.2        5  \n",
       "3296      9.4        5  \n",
       "4524     10.0        6  \n",
       "3640     11.0        6  \n",
       "785       9.3        6  \n",
       "393      12.2        6  \n",
       "562       9.2        6  \n",
       "1285     12.5        6  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "#train = np.genfromtxt('wine_training1.txt', delimiter=',')\n",
    "red = pd.read_csv('winequality-red.csv')\n",
    "white = pd.read_csv('winequality-white.csv')\n",
    "red = shuffle(red, random_state = 10)\n",
    "white = shuffle(white, random_state = 10)\n",
    "red.head(10)\n",
    "white.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "To get this into a binary classification task. We split the quality into a binary feature *good* or *bad* depending on whether the quality is larger than 6 or not.\n",
    "\n",
    "Next we randomly pick $70\\%$ of the data to be our training set and the remaining for testing for both red and white wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4731     True\n",
       "937     False\n",
       "1217    False\n",
       "3296    False\n",
       "4524     True\n",
       "3640     True\n",
       "785      True\n",
       "393      True\n",
       "562      True\n",
       "1285     True\n",
       "Name: quality, dtype: bool"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_red = red.iloc[:, :-1]\n",
    "y_red = red.iloc[:, -1] >= 6\n",
    "\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_red, y_red, test_size=0.3, random_state = 0)\n",
    "\n",
    "X_white = white.iloc[:, :-1]\n",
    "y_white = white.iloc[:, -1] >= 6\n",
    "X_train_white, X_test_white, y_train_white, y_test_white = train_test_split(X_white, y_white, test_size=0.3, random_state = 0)\n",
    "\n",
    "#y_red.head(10)\n",
    "y_white.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Logistic Regression for Red Wine\n",
    "\n",
    "Using scikit learn, train a Logistic Regression classifier using 'X_trn_red, y_trn_red'. Use the\n",
    "solver sag, which stands for Stochastic Average Gradient. Set max iteration to be 10000. Test the model on X_test_red. Output the testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========Your code here ======\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#========================\n",
    "print('The testing error for red wine is: ' + str(error_red) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 Logistic Regression for White Wine\n",
    "\n",
    "Using scikit learn, train a Logistic Regression classifier using 'X_trn_white, y_trn_white'. Use the\n",
    "solver sag, which stands for Stochastic Average Gradient. Set max iteration to be 10000. Test the model on X_test_white. Output the testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========Your code here ======\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#========================\n",
    "print('The testing error for white wine is: ' + str(error_white) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 \n",
    "Use the model you trained using 'X_trn_white, y_trn_white' to test on 'X_test_red' and use the model you trained on 'X_test_white'. Print out the errors and compare with previous results. Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========Your code here ======\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#========================\n",
    "print('The testing error for red wine using white wine training data is: ' + str(error_red) + '.')\n",
    "print('The testing error for white wine using red wine training data is: ' + str(error_white) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 The effect of regularization\n",
    "Using red wine dataset. Implement logistic regression in sklearn, using $\\ell_2$ regularization with regularizer value C in the set $\\{0.00001 \\times 4^i: i = 0,1,2,..., 15\\}$. (The regularization parameter is 'C' in scikit-learn, which is the inverse of $\\lambda$ we see in class). Plot the training error and test error with respect to the regularizer value. Explain what you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.array(range(0,15))\n",
    "alpha = 0.00001*(4**N)\n",
    "error_trn = np.zeros(15)\n",
    "error_tst = np.zeros(15)\n",
    "#========Your code here ======\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#========================\n",
    "plt.figure(1)\n",
    "plt.semilogx(alpha, error_tst,label = 'Test')\n",
    "plt.semilogx(alpha, error_trn, label = 'Train')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
